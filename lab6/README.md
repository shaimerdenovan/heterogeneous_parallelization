## Описание работы

Лабораторная работа №6 посвящена изучению основ программирования на OpenCL и разработке кросс-платформенного приложения для параллельных вычислений. В работе рассматриваются два типовых примера параллельных алгоритмов: элементное сложение векторов и умножение матриц. Основная цель работы это научиться запускать OpenCL-программы на разных типах устройств (CPU и GPU) и сравнить их производительность.

В рамках работы реализованы:
- параллельное сложение двух массивов (vector_add),
- параллельное умножение матриц (mat_mul),
- последовательные CPU-реализации для проверки корректности и сравнения времени выполнения.
## Среда выполнения
Работа выполнялась в среде Google Colab. Это связано с тем, что на моём ноутбуке отсутствует видеокарта NVIDIA, поэтому нет возможности запускать вычисления на GPU локально.
В Google Colab использовались два варианта выполнения:
- OpenCL на CPU с помощью реализации POCL (Portable OpenCL, pthread),
- OpenCL на GPU (Tesla T4), доступный в Google Colab.

Для измерения времени выполнения OpenCL-ядер использовалось профилирование событий OpenCL (cl_event), что позволяет учитывать только время выполнения ядра на устройстве без учёта копирования данных между CPU и GPU.
## Задача 1. Векторное сложение
В первой задаче реализовано параллельное сложение двух массивов A и B длины n с получением массива C, где: C[i]=A[i]+B[i] Каждый work-item OpenCL обрабатывает один элемент массива. Для проверки корректности результат OpenCL сравнивался с последовательной реализацией на CPU.
Эксперименты показали что при выполнении на CPU (OpenCL POCL) время работы ядра больше, чем у оптимизированного последовательного цикла, а при выполнении на GPU (Tesla T4) OpenCL-ядро работает значительно быстрее и даёт ускорение по сравнению с CPU.
## Задача 2. Умножение матриц
Во второй задаче реализовано параллельное умножение матриц: A размером N × M, B размером M × K, результирующая матрица C размером N × K.
Каждый work-item вычисляет один элемент C[row col]. Запуск ядра выполняется в двумерной глобальной области (global size = (K, N)). Корректность результатов проверялась путём сравнения с последовательной реализацией матричного умножения на CPU.
## Сравнение производительности
В ходе экспериментов было получено, что OpenCL на CPU имеет заметные накладные расходы на запуск ядра, OpenCL на GPU показывает значительно лучшую производительность для больших объёмов данных, выигрыш от GPU особенно заметен для простых массовых операций таких как векторное сложение.
## Вывод
В ходе выполнения практической работы были изучены основы программирования на OpenCL и получены навыки запуска параллельных вычислений на CPU и GPU. Эксперименты показали, что GPU обеспечивает существенное ускорение по сравнению с CPU, однако при использовании OpenCL на CPU накладные расходы могут перекрывать выгоду от параллелизма. OpenCL является удобной технологией для создания переносимых параллельных приложений, так как один и тот же код может выполняться на разных типах устройств без изменений.
## Ответы на контрольные вопросы
1. Какие основные типы памяти используются в OpenCL?
В OpenCL используются global memory - общая память устройства, большая, но медленная, local memory - общая память внутри одной рабочей группы, быстрее глобальной, private memory - память одного потока (work-item), используется для временных переменных, constant memory - память только для чтения, используется для неизменяемых данных.

2. Как настроить глобальную и локальную рабочую группу?
Глобальная рабочая группа задаёт общее количество потоков и указывается при запуске ядра. Локальная рабочая группа определяет размер группы потоков (work-group). Локальный размер можно задать вручную или оставить nullptr, тогда OpenCL выбирает его автоматически.

3. Чем отличается OpenCL от CUDA?
OpenCL это кросс-платформенная технология, работает на CPU и GPU разных производителей, а CUDA работает только на видеокартах NVIDIA. OpenCL более универсален, а CUDA обычно быстрее и лучше оптимизирован под GPU NVIDIA.

4. Какие преимущества даёт использование OpenCL?
Возможность запускать один и тот же код на CPU и GPU, независимость от производителя оборудования, подходит для параллельных вычислений и учебных работ, позволяет сравнивать производительность разных устройств.
