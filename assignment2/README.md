## Описание работы
Assignment 2 посвящён изучению гетерогенной параллелизации, а также практическому применению OpenMP и CUDA для ускорения вычислений. Работа состоит из одного теоретического и трёх практических заданий, направленных на сравнение последовательных и параллельных реализаций алгоритмов.

## Задача 1. Введение в гетерогенную параллелизацию

Теоретическое задание (25 баллов) Объясните, что такое гетерогенная параллелизация. В ответе раскройте следующие аспекты:
- различия между параллельными вычислениями на CPU и GPU;
- преимущества гетерогенной параллелизации;
- примеры реальных приложений, в которых используется гетерогенная параллелизация.

Гетерогенная параллелизация это способ ускорять вычисления, когда одновременно используются разные типы устройств, например CPU и GPU. CPU имеет несколько мощных ядер и хорошо справляется с последовательными и сложными задачами, тогда как GPU содержит сотни или тысячи простых ядер, что делает его идеальным для обработки больших массивов данных одновременно. Использование обоих типов устройств позволяет распределять задачи по их особенностям, CPU выполняет логические и управляющие операции, а GPU выполняет массовые вычисления. Это ускоряет работу программ и делает обработку больших объёмов данных более эффективной. Такой подход широко применяется в машинном обучении для тренировки нейросетей, в обработке видео и изображений, а также в научных симуляциях физических процессов.

## Задача 2. Работа с массивами и OpenMP
Для выполнения данной задачи была создана программа, которая создаёт массив из 10 000 случайных чисел и ищет в нём минимальное и максимальное значение. Сначала был выполнен последовательный вариант - просто проход по массиву. Потом был добавлен OpenMP и сделан параллельный вариант с редукцией.

Результаты показали что параллельная версия работает быстрее на многоядерном процессоре, особенно при больших объёмах данных. OpenMP упрощает параллельное выполнение простых циклов и позволяет легко использовать несколько потоков.

## Задача 3. Параллельная сортировка с OpenMP
Для выполнения данной задачи была реализована сортировка выбором для массивов размером 1 000 и 10 000 элементов.
- Последовательная версия выполняет сортировку стандартным алгоритмом.
- Параллельная версия использует OpenMP: каждый поток ищет локальный минимум, а затем в критической секции обновляется глобальный минимум.

Для больших массивов параллельная версия показывает ускорение. Для маленьких массивов накладные расходы на параллелизацию иногда делают выполнение чуть медленнее последовательного метода.
## Задача 4. Сортировка на GPU с использованием CUDA
В этой задаче я реализовала сортировку слиянием на GPU. Идея такая: массив делится на подмассивы, каждый из которых обрабатывается отдельным блоком потоков. После этого выполняется параллельное слияние отсортированных подмассивов, чтобы получить полностью отсортированный массив.

Проверка работы программы была проведена на массивах размером 10 000 и 100 000 элементов. Так как у меня локально CUDA не установлена, весь код тестировался в онлайн-среде LeetGPU Playground. Несмотря на это, удалось увидеть, что сортировка на GPU заметно ускоряет работу с большими массивами по сравнению с последовательной реализацией на CPU.

Для проверки корректности работы сортировки использовалась стандартная функция std::is_sorted. Код правильно обрабатывал все массивы, что подтвердило, что алгоритм работает как надо.

В целом, задача показала, насколько сильно GPU может ускорять вычисления при больших объёмах данных и почему гетерогенная параллелизация (CPU + GPU) так важна в современных вычислительных задачах.
## Выводы
В ходе выполнения задания стало ясно что гетерогенная параллелизация эффективно использует сильные стороны CPU и GPU. CPU хорошо справляется с последовательными задачами а GPU ускоряет массовые параллельные вычисления.

OpenMP позволяет легко выполнять вычисления параллельно на CPU и заметно ускоряет работу с большими массивами, хотя на маленьких накладные расходы могут нивелировать эффект. Сортировка на GPU с помощью CUDA показала значительное ускорение при больших объёмах данных. В целом комбинирование CPU и GPU и правильный выбор инструментов повышают эффективность программ.
