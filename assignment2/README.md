## Описание работы
Assignment 2 посвящён изучению гетерогенной параллелизации, а также практическому применению OpenMP и CUDA для ускорения вычислений. Работа состоит из одного теоретического и трёх практических заданий, направленных на сравнение последовательных и параллельных реализаций алгоритмов.

## Задача 1. Введение в гетерогенную параллелизацию

Теоретическое задание (25 баллов) Объясните, что такое гетерогенная параллелизация. В ответе раскройте следующие аспекты:
- различия между параллельными вычислениями на CPU и GPU;
- преимущества гетерогенной параллелизации;
- примеры реальных приложений, в которых используется гетерогенная параллелизация.

Гетерогенная параллелизация это способ ускорять вычисления, когда одновременно используются разные типы устройств, например CPU и GPU. CPU имеет несколько мощных ядер и хорошо справляется с последовательными и сложными задачами, тогда как GPU содержит сотни или тысячи простых ядер, что делает его идеальным для обработки больших массивов данных одновременно. Использование обоих типов устройств позволяет распределять задачи по их особенностям, CPU выполняет логические и управляющие операции, а GPU выполняет массовые вычисления. Это ускоряет работу программ и делает обработку больших объёмов данных более эффективной. Такой подход широко применяется в машинном обучении для тренировки нейросетей, в обработке видео и изображений, а также в научных симуляциях физических процессов.

## Задача 2. Работа с массивами и OpenMP
Для выполнения данной задачи была создана программа, которая создаёт массив из 10 000 случайных чисел и ищет в нём минимальное и максимальное значение. Сначала был выполнен последовательный вариант - просто проход по массиву. Потом был добавлен OpenMP и сделан параллельный вариант с редукцией.

Результаты показали что параллельная версия работает быстрее на многоядерном процессоре, особенно при больших объёмах данных. OpenMP упрощает параллельное выполнение простых циклов и позволяет легко использовать несколько потоков.

## Задача 3. Параллельная сортировка с OpenMP
Для выполнения данной задачи была реализована сортировка выбором для массивов размером 1 000 и 10 000 элементов.
- Последовательная версия выполняет сортировку стандартным алгоритмом.
- Параллельная версия использует OpenMP: каждый поток ищет локальный минимум, а затем в критической секции обновляется глобальный минимум.

Для больших массивов параллельная версия показывает ускорение. Для маленьких массивов накладные расходы на параллелизацию иногда делают выполнение чуть медленнее последовательного метода.
## Задача 4. Сортировка на GPU с использованием CUDA
В этой задаче я реализовала сортировку слиянием на GPU. Идея такая: массив делится на подмассивы, каждый из которых обрабатывается отдельным блоком потоков. После этого выполняется параллельное слияние отсортированных подмассивов, чтобы получить полностью отсортированный массив.

Проверка работы программы была проведена на массивах размером 10 000 и 100 000 элементов. Так как у меня локально CUDA не установлена, весь код тестировался в онлайн-среде LeetGPU. Несмотря на это, удалось увидеть, что сортировка на GPU заметно ускоряет работу с большими массивами по сравнению с последовательной реализацией на CPU.

Для проверки корректности работы сортировки использовалась стандартная функция std::is_sorted. Код правильно обрабатывал все массивы, что подтвердило, что алгоритм работает как надо.

В целом, задача показала, насколько сильно GPU может ускорять вычисления при больших объёмах данных и почему гетерогенная параллелизация (CPU + GPU) так важна в современных вычислительных задачах.
## Выводы
В ходе выполнения задания стало ясно что гетерогенная параллелизация эффективно использует сильные стороны CPU и GPU. CPU хорошо справляется с последовательными задачами а GPU ускоряет массовые параллельные вычисления.

OpenMP позволяет легко выполнять вычисления параллельно на CPU и заметно ускоряет работу с большими массивами, хотя на маленьких накладные расходы могут нивелировать эффект. Сортировка на GPU с помощью CUDA показала значительное ускорение при больших объёмах данных. В целом комбинирование CPU и GPU и правильный выбор инструментов повышают эффективность программ.

## Ответы на контрольные вопросы
1. Что понимается под гетерогенной параллелизацией?
Это когда для одной задачи одновременно используют разные типы устройств, например CPU и GPU, чтобы быстрее решать вычисления.
2. В чём принципиальные различия архитектур CPU и GPU?
CPU имеет несколько мощных ядер и хорошо справляется с последовательными и сложными задачами, а GPU имеет сотни или тысячи простых ядер которые отлично подходят для параллельной обработки больших массивов данных.
3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?
GPU хорошо работает с массовыми параллельными операциями например сортировка больших массивов, обработка изображений, машинное обучение. CPU лучше подходит для сложной логики, последовательных вычислений и управления программой.
4. Почему не все алгоритмы эффективно распараллеливаются с использованием
OpenMP?
Потому что некоторые алгоритмы сильно зависят от последовательного порядка вычислений или имеют много ветвлений, тогда параллельность может не дать ускорения или даже замедлить выполнение.
5. В чём заключается основная идея алгоритма сортировки слиянием?
Массив делят на маленькие части, сортируют каждую отдельно, а потом объединяют обратно в один отсортированный массив. Это пример принципа «разделяй и властвуй».
6. Какие сложности возникают при реализации сортировки слиянием на GPU?
Массив делят на маленькие части, сортируют каждую отдельно, а потом объединяют обратно в один отсортированный массив. Это пример принципа «разделяй и властвуй».
7. Как выбор размера блока и сетки влияет на производительность вычислений на
GPU?
Если блоки и сетка слишком маленькие то GPU простаивает, если слишком большие то потоки начинают мешать друг другу, и производительность падает. Нужно подобрать оптимальное соотношение, чтобы все ядра были заняты.
8. Почему гетерогенный подход может быть эффективнее использования только
CPU или только GPU?
Потому что CPU и GPU хорошо подходят для разных типов задач и используя их вместе можно распределять работу так чтобы каждая часть выполнялась быстрее и эффективнее.
