## Описание работы 
В данной практической работе №9 изучается библиотека MPI, которая используется для параллельного программирования. Целью работы является научиться распределять данные между процессами, выполнять вычисления параллельно и собирать результаты. В рамках работы были реализованы три программы на языке C++ с использованием MPI:
1. Вычисление среднего значения и стандартного отклонения большого массива.
2. Решение системы линейных уравнений методом Гаусса.
3. Поиск кратчайших путей в графе с помощью алгоритма Флойда–Уоршелла.
Все программы запускались в среде Google colab. Для измерения времени выполнения использовалась функция MPI_Wtime().

#### Задание 1
На процессе с номером rank=0 создаётся массив случайных чисел. Этот массив делится между процессами с помощью MPI_Scatterv, так как размер массива может не делиться нацело. Каждый процесс считает сумму элементов своей части массива и считает сумму квадратов элементов.
После этого все локальные суммы собираются на процессе rank=0 с помощью MPI_Reduce, где вычисляются среднее значение и стандартное отклонение.

#### Задание 2
Процесс rank=0 создаёт матрицу коэффициентов и вектор правых частей. Строки матрицы распределяются между процессами с помощью MPI_Scatter. Во время прямого хода метода Гаусса каждый процесс обрабатывает только свои строки, опорная строка передаётся другим процессам через MPI_Bcast.
После завершения прямого хода все данные собираются на процессе rank=0, где выполняется обратный ход и выводится решение системы.

#### Задание 3
Процесс rank=0 создаёт матрицу смежности графа. Строки матрицы распределяются между процессами с помощью MPI_Scatter. На каждой итерации алгоритма Флойда–Уоршелла каждый процесс обновляет свою часть матрицы, обновлённые данные передаются всем процессам с помощью MPI_Allgather.
После завершения всех итераций итоговая матрица кратчайших путей выводится на процессе rank=0.

## Вывод
В ходе работы были реализованы три параллельные программы на языке C++ с использованием библиотеки MPI. Все программы корректно отработали и выдали ожидаемые результаты. В первом задании были правильно вычислены среднее значение и стандартное отклонение массива. Во втором задании была успешно решена система линейных уравнений методом Гаусса. В третьем задании был реализован алгоритм Флойда-Уоршелла для поиска кратчайших путей в графе. Работа показала, что использование MPI позволяет ускорить вычисления за счёт распределения данных между процессами, однако эффективность зависит от количества процессов и объёма передаваемых данных.

## Ответы на контрольные вопросы
1. Как изменяется время выполнения программы при увеличении количества процессов? Почему?
При увеличении количества процессов время выполнения обычно уменьшается, так как работа делится между процессами. Но при большом числе процессов ускорение становится меньше из-за затрат времени на обмен данными.

2. Какие факторы могут влиять на производительность программы?
На производительность влияют количество процессов, объём обрабатываемых данных, количество обменов данными между процессами, равномерность распределения нагрузки.

3. Как можно оптимизировать передачу данных между процессами?
Передачу данных можно улучшить, если уменьшать объём передаваемых данных, использовать коллективные операции MPI, уменьшать количество синхронизаций между процессами.

4. Какие ограничения возникают при работе с большими данными?
При работе с большими данными могут возникать нехватка памяти, рост времени обмена данными, снижение эффективности при большом числе процессов.
